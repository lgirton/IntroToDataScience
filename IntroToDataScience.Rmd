---
title: "Intro to Data Science: NYC Subway Ridership Patterns"
author: "Lamont Girton"
date: "October 21, 2015"
output: 
  pdf_document: 
    fig_caption: yes
documentclass: article
classoptions: a4paper
fontsize: 12pt
bibliography: bibliography.bib
csl: algorithmica.csl
header-includes:
    - \usepackage{graphicx}
    - \usepackage{float}
    - \usepackage{lipsum}
    - \usepackage{url}
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}

library(knitr)
options(digits=2,scipen = 100)
opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.align="center", fig.pos="H")

library(ggplot2)
library(dplyr)
library(tidyr)
library(lubridate)
library(xtable)
library(caret)
library(scales)
library(ggmap)

set.seed(1)
```


```{r, cache=TRUE}

turnstile <- read.csv("./turnstile_weather_v2.csv")

colnames(turnstile) <- tolower(colnames(turnstile))

turnstile$date <- as.Date(turnstile$daten, "%m-%d-%y")

turnstile$datetime <-
  as.POSIXct(strptime(paste(turnstile$date,turnstile$timen), "%F %H:%M:%S"))

turnstile$day_week <- factor(weekdays(turnstile$date, abbr = T), levels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))

turnstile$weekday <-
  as.logical(!(turnstile$day_week %in% c("Sun", "Sat")))

turnstile$entries <- turnstile$entriesn_hourly
turnstile$exits <- turnstile$exitsn_hourly
turnstile$rain <- factor(turnstile$rain, labels = c("No Rain", "Rain"))
turnstile$rain <- relevel(turnstile$rain, "Rain")
turnstile$hour <- turnstile$hour

turnstile <-
  select(turnstile,-daten,-timen,-entriesn,-entriesn_hourly,-exitsn,-exitsn_hourly)

```

# Introduction

As part of the Udacity's [_Intro to Data Science_](https://www.udacity.com/course/viewer#!/c-ud359-nd) course, NYC Subway Ridership data was obtained from the New York City Metropolitan Transportation Authority and combined with historical weather data from the Weather Underground to perform some statistical analysis.  The first part of the paper will use non-parametric statistical tests to determine if the effect of rain is statistically significant on ridership on the NYC subway.  The paper will go on to generate Linear and Poisson Regression models to predict ridership based on features in the provided data set.  We will conclude this paper with summary of the results and reflect any potential shortcomings in the data or analysis.

I used the "Improved data set" for this analysis and it can be found [here](https://www.dropbox.com/s/1lpoeh2w6px4diu/improved-dataset.zip?dl=0).  This document was generated using R and Rmarkdown and the source document is available on GitHub at https://github.com/lgirton/IntroToDataScience/IntroToDataScience.Rmd.


# Does Ridership increase on rainy days?

During the _Intro To Data Science_ course, we probed the question of whether Subway ridership increased during rainy days, versus the days it did not rain and if this increase was statistically significant (at the 95% level) or due to random chance in sampling. Our intuition is that the effect of rain will positively increase ridership as people abandon alternative modes of transportation (walking, cycling, etc.) that would otherwise expose them to inclement weather.  The null and alternative hypothesis are listed below:

> $H_0: \text{There is no difference between ridership on rainy and non-rainy days.}$
\newline
> $H_a: \text{There is an increase in ridership on rainy days.}$


This is a _one-tailed test_, because we're testing for the presence of a _positive_ difference in ridership (dependent variable) due to rain (independent variable).  The table below shows the mean and median of the number number of entries on the subway and from this data, we can see that the distribution is high-skewed to the right (The mean is substantially further to the right than the mean). 

```{r, fig.cap="Histogram of Subway Ridership for Rainy and Non-Rainy days.  The distributions are highly skewed to the right and non-normal."}

ggplot(turnstile, aes(entries, fill = rain)) +
  geom_histogram(color = "black") +
  facet_wrap( ~ rain, nrow = 2) +
  theme(legend.position = 'none') +
  xlab("Hourly Entries") +
  ylab("Frequency") +
  ggtitle("Histogram of Station Hourly Entries for Rainy and Non-Rainy Days")

```

```{r, results='asis'}

# Function to bold column names in xtable
bold <- function(x) {
  paste("\\textbf{",x,"}")
}

# Summary statistics for rain vs. no-rain
turn_summary <- group_by(turnstile, Rain=rain) %>% 
  summarise(Mean=mean(entries), Median=median(entries), `Std. Dev.`=sd(entries))

cap <- "Summary statistics on ridership on rainy and non-rainy days."
# xtable
tab <- xtable(turn_summary, align = "|l|l|r|r|r|", digits = 2, caption = cap)

# Print xtable
print.xtable(tab, table.placement = "H", sanitize.colnames.function = bold, comment = F, include.rownames = F)

```

```{r, cache = T}
mww <- wilcox.test(entries ~ rain, turnstile, alt="greater")
U <- mww$statistic
pvalue <- mww$p.value
```
Because of this skewedness, we'll forego the standard two Sample t-Test in favor of the the Mann-Whitney U [@wiki:mannwhitney; @scipy:mannwhitney] test to determine whether the difference in the mean (medians) is significant.  The p-critical value for this test is 0.05 and to consider if there is a statistically significant difference in a one-sided test, the p-value should fall below this critical value ($p < 0.05$).  The results of the Mann-Whitney U showed that a positive effect of rain with respect to ridership was significant at the 0.05 level ($U = `r U`, p = `r format(pvalue, scientific=T)`$).  The \emph{p-value} of $`r format(pvalue, scientific=T)`$ is substantially lower than the critical value of 0.05 and approximately 0.


# Predicting Subway Ridership using Regression

This section will explore using Multiple Linear Regression to generate a model for predicting subway ridership in New York City based on meteorological, spatial and temporal features of the provided data set.  The dependent variable in this model will be the _Number of Entries_ at the subway station.  In analyzing the data, I speculate that the following features should contribute as predictors in the model: 

* Station
* Day of Week
* Time Of Day
* Weather
    - Rain
    - Mean Temperature

## Station

```{r}
entries_max <- max(turnstile$entries)
```


Some stations will undoubtedly have differences in average volume of entries based on their proximity to business centers, etc.  There were `r nlevels(turnstile$unit)` unique stations in the data.  The max number of entries in the data set was `r entries_max ` and the minimum was `r min(turnstile$entries)`, with a standard deviation of `r sd(turnstile$entries)`. 

```{r, results='asis'}
top_stations <- turnstile %>% 
    group_by(Unit=unit,Station=station) %>% 
    summarise(`Avg. Hourly Entries`=mean(entries)) %>% 
    ungroup() %>% 
    arrange(desc(`Avg. Hourly Entries`)) %>% 
    top_n(5)

cap <- "Top 5 Stations by average number of entries."
tab <- xtable(top_stations, cap, align = "|l|l|l|r|", digits = 2)

print.xtable(tab, table.placement = "H", include.rownames = F, comment = F, sanitize.colnames.function = bold)
```

```{r, results='asis'}
bottom_stations <- turnstile %>% 
    group_by(Unit=unit,Station=station) %>% 
    summarise(`Avg. Hourly Entries`=mean(entries)) %>% 
    ungroup() %>% 
    arrange(`Avg. Hourly Entries`) %>% 
    head(5)

cap <- "Bottom 5 Stations by average number of entries."
tab <- xtable(bottom_stations, cap, align = "|l|l|l|r|", digits = 2)

print.xtable(tab, table.placement = "H", include.rownames = F, comment = F, sanitize.colnames.function = bold)
```

The map below was generated using the _ggmap_ R package [@article:ggmap].  This map helps to illustrate the differences in average entries across the stations (and city).  From the figure, we see that the stations with higher average entries are concentrated in Midtown, Manhattan and this follows the intuition, that Midtown is the center of industry and business and many of those that work there don't or can't afford to live there and choose the subway to commute there.

```{r, cache=T, fig.cap="Map of New York City overlayed with average ridership by UNIT.  Stations with higher average ridership appear to be concentrated in Midtown."}

midpoint <- function(x) {
    min_x <- min(x)
    max_x <- max(x)
    
    return( min_x + (max_x - min_x) / 2 )
}

unit_summary <- group_by(turnstile, longitude, latitude, unit) %>% 
    summarise(entries=mean(entries))

lon_mid <- midpoint(unit_summary$longitude)
lat_mid <- midpoint(unit_summary$latitude)

map <- get_map(location = c(lon_mid, lat_mid), zoom = 11)

ggmap(map, legend = "none") +
    geom_point(data=unit_summary, aes(longitude, latitude, size=entries, color=entries)) +
    theme(legend.position="right", axis.text = element_blank(), axis.title = element_blank()) +
    ggtitle("Average Hourly Entries by Unit")

```

## Day of Week

The day of the week also appeared to influence ridership.  From the plot below, the average number of entries peaked on Friday.  There also mean ridership appears to be higher on weekdays than on weekends and this is probably influenced by people commuting to work during the week.

```{r, fig.cap="Barchart of Average Ridership by Weekday. Ridership appears lower on weekends as opposed to weekdays."}
ggplot(turnstile, aes(day_week, entries)) +
  stat_summary(fun.y=mean, geom = "bar", color="black", fill="salmon") +
  xlab("Weekday") +
  ylab("Avg. Hourly Entries") +
  ggtitle("Mean Hourly Entries by Day of Week")
```

## Time of Day

During the course, we also explored the effect of the time of day on ridership.  Below is a plot of the average number of entries by 4-hour periods.  The plot is bi-modal with the average number of entries peaking around Noon and around 8pm in the evening.

```{r, fig.cap = "Mean hourly station entries by time of day.  Ridership peaks at 12p and 8p during the day."}

ggplot(turnstile, aes(hour, entries, color=day_week)) +
    stat_summary(fun.y=mean, geom="line") +
    xlab("Hour") +
    ylab("Avg. Hourly Entries") +
    ggtitle("Mean Hourly Entries by Hour and Day")
```

## Weather

### Rain
We already explored the effect of rain on ridership in the _Statistical Test_ section of this document and based on the findings will include this feature in the model.

### Mean Temperature

I'm hypothesizing that temperature plays a role in ridership on the subways in NYC as ridership might be higher when the weather is relatively colder or hotter that would influence riders to take the subway as alternatives to say walking or riding a bicycle.  Below is a scatter plot of ridership versus the mean temperature during the 4 hour period.  There doesn't appear to be a linear relationship between the two, but hoping that the non-linearity can be explained through the regression model by other factors (Day of Week, Hour, etc.).

```{r, cache=T, fig.cap="Scatterplot of Mean Temperature v. Ridership.  Ridership appears to be higher in the lower and upper temperature bands"}
ggplot(turnstile, aes(meantempi, entries)) +
    geom_point(alpha=0.4, position = position_jitter()) +
    xlab("Temperature (F)") +
    ylab("Hourly Entries") +
    ggtitle("Scatterplot of Hourly Entries by Temperature (F)")
```

## Model Fitting

I will use R to perform the linear regression model fitting and will randomly divide the data set up into a _training_ and _testing_ set with a 75% split for the training and 25% for testing.  I will use Root Mean Squared Error[@wiki:rmse] (RMSE) to evaluate performance of the model against the test data set.

```{r}
idx <- sample(nrow(turnstile), floor(nrow(turnstile)*.75))
train <- turnstile[idx, ]
test <- turnstile[-idx, ]
```

```{r, cache=F, echo=TRUE}
fit <- lm(entries ~ unit + day_week + hour + rain + meantempi, train)
```

```{r}
fit.summary <- summary(fit)
fit.coef <- fit.summary$coefficients

pred <- predict.lm(fit, test)
perf <- RMSE(pred,test$entries)

perf.naive <- RMSE(mean(train$entries), test$entries)

```

Below is a table of the intercept and the coefficients from the linear model.  I have excluded the _unit_ dummy variables from the table, as there were 239 coefficients.  The model had an $R^2$ value of `r fit.summary$r.squared` and a $RMSE = `r perf`$.  The $R^2$ value means that `r percent(fit.summary$r.squared)` of the variance in the response variable can be explained the features selected in the data set.  As a baseline to compare the performance of the linear model with, I calculated the RMSE of using the mean as the predicted value for all entries in the test set and this produced a RMSE of `r perf.naive` which was greater than that of the linear model fit.


```{r, results='asis'}
cap <- "Table of the model Intercept and coefficients for a subset of the predictor variables.  Omitted coefficients for the \\emph{unit} dummy variables as there were 239 of them."
tab <- xtable(fit.coef[grep("^unit", rownames(fit.coef), invert = T),], caption = cap, digits = 4, align = "|l|r|r|r|r|")
print.xtable(tab, table.placement = "H", comment = F, sanitize.colnames.function = bold)
```

I had observed that some of the predictions made by this model were negative, a scenario that doesn't make sense in the real world.  In these cases, it would probably make sense to interpret these values as zero or use Poisson Regression [@wiki:poisson; @ucla:poisson].

```{r, cache = T}

fit.poisson <- glm(entries ~ unit + day_week + hour + rain + meantempi, train, family = poisson())

pred.poisson <- predict(fit.poisson, test)

perf.poisson <- RMSE(exp(pred.poisson), test$entries)

```

## Goodness of fit

Below is a table RMSE for three models.  Of the three, the _Poisson Regression_ model had the lowest error.

|Model|RMSE|
|:----|---:|
|Naive|`r perf.naive`|
|Linear Regression|`r perf`|
|Poisson Regression|`r perf.poisson`|

Below is a density plot of show the distribution of the entries of the Actual entries from the test data set, as well as the distribution of the predictions from the Linear and Poisson Regression models.  The Poisson Regression model has a shape (better fit) more consistent with the actual shape of ridership.

```{r, fig.cap="Comparision of the prediction distributions of the Linear and Poisson Regression models to actual ridership in the test dataset.", fig.width=5}

model_dist <- data.frame(Distribution="Actual", entries=test$entries)

model_dist <- rbind(model_dist, data.frame(Distribution="Linear", entries=pred))

model_dist <- rbind(model_dist, data.frame(Distribution="Poisson", entries=exp(pred.poisson)))

ggplot(model_dist, aes(entries, fill=Distribution, color=Distribution)) + 
    geom_density(alpha=0.5) + 
    xlab("Hourly Entries") +
    ylab("Density") +
    theme(legend.position="bottom") +
    ggtitle("Distribution of Regression Predictions v. Actual")

```

# Conclusion

In conclusion, we determined that there was positive (# of entries increased on average) effect of rain on ridership and this effect was significant at the 0.05 level ($U = `r U`, p = `r format(pvalue, scientific=T)`$).  The \emph{p-value} of $`r format(pvalue, scientific=T)`$ is substantially lower than the critical value of 0.05 and approximately 0.

We also generated Linear and Poisson Regression models that incorporated spatial, temporal and meteorological features in the data to generate predictions that performed on average better than a naive approach of using the mean of the entire data set.

# Reflection

The data used for this analysis were confined to the month of `r strftime(min(turnstile$date), "%B")` of `r strftime(min(turnstile$date), "%Y")` and it would have been helpful to generate a predictive model that included a larger window of time to determine if there were any seasonal effects or longer term underlying trends.  In addition to the data, the features I selected for inclusion into the model were chosen based intuition (guessing) about there contributions to the model.  It would be worthwhile to investigate techniques for _Automated Feature Selection_ and more in-depth analysis of the features and interactions with other dependent variables to produce a better fitting model.

# References
